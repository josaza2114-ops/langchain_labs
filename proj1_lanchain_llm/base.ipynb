{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5fea76c",
   "metadata": {},
   "source": [
    "# RAG Architecture\n",
    "\n",
    "Two main components:\n",
    "-Indexing\n",
    "-Retrieval and generation\n",
    "\n",
    "## Indexing\n",
    "1. Load the data: this is done with DocumentLoaders\n",
    "2. Split the data into smaller chunks\n",
    "3. Store: you need somewhere to store and index your splits, this can be done using a VectorStore and Embeddings\n",
    "\n",
    "## Retrieval and generation\n",
    "1. Retrieve: Given the ser input relevant splits are retrieved from storage using a retriever\n",
    "2. Generate: a chatmodel/llm producs the answer using a prompt that includes the question and the retrieved data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864f2e25",
   "metadata": {},
   "source": [
    "First make sure you have the needed libraries\n",
    "```bash\n",
    "pip install ibm-watsonx-ai==0.2.6 langchain==0.1.16 langchain-ibm==0.1.4 transformers==4.41.2 huggingface-hub==0.23.4 sentence-transformers==2.5.1 chromadb wget==3.2 --upgrade torch --index-url https://download.pytorch.org/whl/cpu\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5caae823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DATA_DIR: C:\\Users\\Jose\\Documents\\GitHub\\langchain_labs\\proj1_lanchain_llm\\data\n",
      "DB_DIR: C:\\Users\\Jose\\Documents\\GitHub\\langchain_labs\\proj1_lanchain_llm\\chroma_db\n",
      "EMBED_MODEL: sentence-transformers/all-MiniLM-L6-v2\n",
      "CHUNK_SIZE=800, CHUNK_OVERLAP=120\n",
      "\n",
      "Gemini ping: Pong.\n"
     ]
    }
   ],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os, sys, textwrap\n",
    "import google.generativeai as gen\n",
    "from dotenv import load_dotenv\n",
    "# Core libs we installed\n",
    "import torch, transformers, chromadb, tokenizers, numpy as np\n",
    "import langchain\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "import wget\n",
    "\n",
    "load_dotenv()\n",
    "DATA_DIR   = Path(\"./data\")        # Put your .txt/.md here (we'll add PDF later)\n",
    "DB_DIR     = Path(\"./chroma_db\")   # On-disk Chroma store\n",
    "EMBED_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "CHUNK_SIZE, CHUNK_OVERLAP = 800, 120\n",
    "\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "DB_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"\\nDATA_DIR:\", DATA_DIR.resolve())\n",
    "print(\"DB_DIR:\", DB_DIR.resolve())\n",
    "print(\"EMBED_MODEL:\", EMBED_MODEL)\n",
    "print(f\"CHUNK_SIZE={CHUNK_SIZE}, CHUNK_OVERLAP={CHUNK_OVERLAP}\")\n",
    "\n",
    "# --- Gemini API key + model selection ---\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "gen.configure(api_key=api_key)\n",
    "\n",
    "\n",
    "\n",
    "# Quick health check: minimal ping\n",
    "pong = gen.GenerativeModel(\"gemini-2.0-flash\").generate_content(\"Say 'pong'.\").text.strip()\n",
    "print(\"\\nGemini ping:\", pong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bad0234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file downloaded\n"
     ]
    }
   ],
   "source": [
    "filename = 'companyPolicies.txt'\n",
    "url = 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/6JDbUb_L3egv_eOkouY71A.txt'\n",
    "\n",
    "# Use wget to download the file\n",
    "wget.download(url, out=\"data/\"+filename)\n",
    "print('file downloaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de2d4766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file downloaded\n"
     ]
    }
   ],
   "source": [
    "\n",
    "filename = 'toSummarize.txt'\n",
    "url = 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/XVnuuEg94sAE4S_xAsGxBA.txt'\n",
    "\n",
    "# Use wget to download the file\n",
    "wget.download(url, out=\"data/\"+filename)\n",
    "print('file downloaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f5a62c",
   "metadata": {},
   "source": [
    "## Upload docs and Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255ded4d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain_community'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m List\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mschema\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Document\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_community\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdocument_loaders\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DirectoryLoader, TextLoader\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m  \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtext_splitter\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CharacterTextSplitter\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_community\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01membeddings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HuggingFaceEmbeddings\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'langchain_community'"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from typing import List\n",
    "from langchain.schema import Document\n",
    "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
    "from  langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "loader = TextLoader(filename)\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "print(len(texts))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".LVenv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
